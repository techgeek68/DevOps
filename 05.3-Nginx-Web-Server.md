## Nginx Web Server

* Free, open source, cross platform (Runs on Linux, Windows, macOS, Unix, and other operating systems) web server. Created by Igor Sysoev to solve the C10K problem (handling 10,000+ concurrent connections), now maintained by F5 Networks. Widely used in modern web infrastructure and cloud native deployments. Powers a significant portion of the world's high traffic websites.

* Basic Operation
  * Non blocking async processing allows a single worker process to handle thousands of concurrent connections efficiently.
    * Listens on HTTP (port 80) and HTTPS (port 443) by default
    * Receives incoming client requests
    * Routes requests based on server blocks (domain/IP) and location blocks (URI paths)
    * Processes requests asynchronously handles multiple connections simultaneously without blocking
    * Returns responses directly to clients or proxies requests to backend servers
    * Maintains event loop for efficient connection handling

* Architecture:
  * Event Driven Model:
    * Single threaded event loop with non-blocking I/O handling thousands of simultaneous connections with minimal memory usage.

  * Master Worker Process:
    * The master process manages configuration and workers; worker processes handle requests asynchronously without blocking each other.

  * Performance:
    * Significantly lower memory footprint and more predictable resource usage compared to thread based servers.
      
* Features:
  * Reverse Proxy & Load Balancing
    * Forwards requests to backend servers (Node.js, Tomcat, Java, etc.)
    * Multiple algorithms:
      * round robin, least connections, IP hash, weighted
    * Session persistence and sticky sessions support

  * SSL/TLS & Security
    * Handles SSL/TLS termination for HTTPS
    * HTTP/2 support for improved performance
    * HTTP/3 via QUIC (experimental in mainline from v1.25.0+)
    * TLS 1.3 support

  * Static Content Serving
    * Sendfile zero copy for efficient file transmission
    * Gzip compression for bandwidth reduction
    * HTTP caching with conditional request support
      * Reducing load on backend servers, Supports conditional requests (ETags, Last-Modified headers), configurable cache expiration policies Cache purging, and validation.
    * Extremely high performance for static files

  * Flexible Configuration
    * Simple, readable syntax with server and location blocks
    * Virtual hosting support (multiple sites on a single instance)
    * URL rewriting and dynamic routing
    * Per-location security, redirects, and custom behaviors

  * Extensibility
    * Modular design & Lightweight core with optional functionality
      * Extensible via modules (core modules and third-party modules).
      * Common modules include:
        * ngx_http_proxy_module (proxying)
        * ngx_http_rewrite_module (URL rewriting and redirects)
        * ngx_http_gzip_module (compression)
        * ngx_http_ssl_module (SSL/TLS support)
        * ngx_stream_module (TCP/UDP load balancing)
        * ngx_http_auth_basic_module (basic authentication) Minimal core with optional functionality, Lower memory and CPU overhead compared to traditional web servers 

* Uses
  * Static & Dynamic Website Hosting
    * Serves static files efficiently; proxies dynamic requests to backend servers
  * Reverse Proxy & Load Balancing
    * Distributes traffic across multiple backend servers with SSL/TLS termination
  * API Gateway
    * Handles RESTful APIs, rate limiting, authentication, and response caching
  * Content Delivery
    * Acts as an edge cache to accelerate content delivery HTTP caching, and conditional request handling Bandwidth optimization through compression
  * Microservices & Container Orchestration
    * Widely used in Kubernetes as an ingress controller Load balancing for containerized applications Service mesh integration (Istio, Linkerd, etc.) Perfect for cloud native and Docker based deployments.
  * Development & Testing
    * Lightweight and low resource consumption, suitable for development environments. Rapid local development setup without a heavy footprint. Easy configuration for testing various server scenarios.


**Installation and Setup**
  - Install Nginx
```bash
sudo dnf install nginx -y
```
  - Start, enable, and check status
```bash
sudo systemctl enable nginx --now
sudo systemctl status nginx
```
  - Firewall configuration
```bash
sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --reload
```

**Configuration Structure**
```bash
tree /etc/nginx
```
```text
/etc/nginx/                                           # Main NGINX configuration directory
├── conf.d/                                           # Extra configuration files loaded automatically
├── default.d/                                        # Default server config snippets included by nginx.conf
├── fastcgi.conf                                      # FastCGI parameters for PHP or other backends
├── fastcgi_params                                    # Legacy FastCGI parameter definitions
├── mime.types                                        # Maps file extensions to MIME types
├── nginx.conf                                        # Primary NGINX configuration file
└── (plus various *.default and encoding files)       # Backup and charset mapping files
```


**Configuration File**
 - It defines global NGINX behavior and tells NGINX where to find additional configuration files.
 
`sudo vim /etc/nginx/nginx.conf`

```nginx
# nginx.conf core structure
events {                                         # Controls general connection handling
    worker_connections 1024;                     # Maximum simultaneous connections per worker
}

http {                                           # Main HTTP configuration block
    include /etc/nginx/mime.types;               # Loads file type mappings (MIME types)
    include /etc/nginx/conf.d/*.conf;            # Includes all site/server configs from conf.d/
    include /etc/nginx/sites-enabled/*;          # Includes enabled virtual host files (if used)
}
```


**Basic Configuration (Nginx Server Block)**

 - This is a server block (sometimes called a virtual host). It defines how NGINX should respond to requests for a specific domain or IP.
 - Syntax:

```nginx
server {                                      # Defines a virtual host or website block
    listen <port>;                            # Port number to listen on (e.g., 80 or 443)
    server_name <domain_or_IP>;               # Domain name or IP address to respond to
    root <document_root_path>;                # Directory containing website files
    index <index_file>;                       # Default file served when accessing the site

    location <path> {                         # Defines how to handle specific request paths
        <directive> <value>;                  # Configuration directive(s) for this path
        ...                                   # Additional directives if needed
    }
}
```

**Example 1: Static Web Server**

 - Create site directory
```bash
sudo mkdir -p /usr/share/nginx/devops
```

`sudo vim /usr/share/nginx/devops/index.html`

```bash
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Nginx web server status dashboard">
    <title>Nginx Status Dashboard</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        .dashboard {
            background: white;
            border-radius: 16px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
            max-width: 600px;
            width: 100%;
        }
        .header {
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            color: white;
            padding: 40px 30px;
            text-align: center;
        }
        .header h1 {
            font-size: 32px;
            margin-bottom: 10px;
            font-weight: 700;
        }
        .header p {
            font-size: 14px;
            opacity: 0.9;
            letter-spacing: 0.5px;
        }
        .content {
            padding: 50px 30px;
            text-align: center;
        }
        .status-container {
            margin-bottom: 40px;
        }
        .status-icon {
            font-size: 72px;
            margin-bottom: 20px;
            display: block;
        }
        .status-title {
            font-size: 28px;
            color: #2c3e50;
            margin-bottom: 20px;
            font-weight: 600;
        }
        .status-badge {
            display: inline-flex;
            align-items: center;
            gap: 10px;
            background: #d5f4e6;
            color: #27ae60;
            padding: 12px 24px;
            border-radius: 8px;
            font-weight: 600;
            font-size: 16px;
        }
        .status-dot {
            width: 12px;
            height: 12px;
            background-color: #27ae60;
            border-radius: 50%;
            animation: pulse 2s infinite;
        }
        .details-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 40px;
            padding-top: 40px;
            border-top: 1px solid #ecf0f1;
        }
        .detail-item {
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
        }
        .detail-label {
            font-size: 12px;
            color: #7f8c8d;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 8px;
            font-weight: 600;
        }
        .detail-value {
            font-size: 18px;
            color: #2c3e50;
            font-weight: 700;
        }
        .footer {
            background: #f8f9fa;
            padding: 20px 30px;
            text-align: center;
            border-top: 1px solid #ecf0f1;
            font-size: 13px;
            color: #7f8c8d;
        }
        .footer a {
            color: #667eea;
            text-decoration: none;
        }
        .footer a:hover {
            text-decoration: underline;
        }
        @keyframes pulse {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.6;
            }
        }
        @media (max-width: 600px) {
            .header {
                padding: 30px 20px;
            }
            .header h1 {
                font-size: 24px;
            }
            .content {
                padding: 30px 20px;
            }
            .status-icon {
                font-size: 56px;
            }
            .status-title {
                font-size: 22px;
            }
            .details-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="dashboard">
        <div class="header">
            <h1>Nginx Web Server</h1>
            <p>Real-time Status Monitor</p>
        </div>

        <div class="content">
            <div class="status-container">
                <span class="status-icon">✓</span>
                <h2 class="status-title">All Systems Operational</h2>
                <div class="status-badge">
                    <span class="status-dot"></span>
                    Nginx is running successfully
                </div>
            </div>

            <div class="details-grid">
                <div class="detail-item">
                    <div class="detail-label">Service Status</div>
                    <div class="detail-value">Online</div>
                </div>
                <div class="detail-item">
                    <div class="detail-label">Uptime</div>
                    <div class="detail-value">Stable</div>
                </div>
                <div class="detail-item">
                    <div class="detail-label">Server</div>
                    <div class="detail-value">Active</div>
                </div>
                <div class="detail-item">
                    <div class="detail-label">Response Time</div>
                    <div class="detail-value">Optimal</div>
                </div>
            </div>
        </div>

        <div class="footer">
            <p>Last updated: <span id="update-time">Just now</span> | <a href="#">View Logs</a></p>
        </div>
    </div>

    <script>
        // Update the timestamp
        function updateTimestamp() {
            const now = new Date();
            const timeString = now.toLocaleTimeString('en-US', {
                hour: '2-digit',
                minute: '2-digit',
                second: '2-digit'
            });
            document.getElementById('update-time').textContent = timeString;
        }

        // Initial update
        updateTimestamp();

        // Update every second
        setInterval(updateTimestamp, 1000);
    </script>
</body>
</html>
```

 - Nginx Server Block:
   
    `sudo vim /etc/nginx/conf.d/devops.conf`
 
```nginx
server {                                                 # Defines a virtual host (website) configuration
    listen 80;                                            # Listens on port 80 for HTTP requests
    listen [::]:80;
    server_name 192.168.64.4 www.devops.com 127.0.0.1 localhost;             # Responds to these domain names or IPs
    root /usr/share/nginx/devops;                                            # Root directory for website files
    index index.html index.htm;                                              # Default index files to serve

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;                  # Prevents clickjacking (same origin only)
    add_header X-XSS-Protection "1; mode=block" always;              # Enables XSS filtering in browsers
    add_header X-Content-Type-Options "nosniff" always;              # Blocks MIME type sniffing

    # Logging
    access_log /var/log/nginx/devops_access.log;                     # Log file for successful requests
    error_log /var/log/nginx/devops_error.log;                       # Log file for errors

    location / {                                                     # Defines behavior for requests to the site root
        try_files $uri $uri/ =404;                                   # Serve file if exists, else return 404
    }

    # Deny access to hidden files
    location ~ /\. {                                     # Matches hidden files (starting with .)
        deny all;                                        # Denies access to such files
        access_log off;                                  # Disables access logging for them
        log_not_found off;                               # Prevents logging missing hidden files
    }
}
```

 - Test configuration
```bash
sudo nginx -t
```

 - Restart Nginx
```bash
sudo systemctl restart nginx
```

Test: `http://127.0.0.1/`

![Screenshot 2026-01-29 at 11 57 31 AM](https://github.com/user-attachments/assets/0dac0294-06ed-470d-b252-7a1683345715)



---
**10 SSL/TLS Configuration**

```nginx
server {
    listen 443 ssl http2;
    server_name example.com;
    
    ssl_certificate /etc/ssl/certs/example.com.crt;
    ssl_certificate_key /etc/ssl/private/example.com.key;
    
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    
    # HSTS
    add_header Strict-Transport-Security "max-age=63072000" always;
}
```

**Security Headers**
```nginx
server {
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header Referrer-Policy "no-referrer-when-downtrade" always;
    add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;
}
```


---

**Performance Tuning**

 - Worker Configuration
```nginx
# nginx.conf
worker_processes auto;        # Match CPU cores
worker_rlimit_nofile 65536;   # File descriptors

events {
    worker_connections 8192;  # Connections per worker
    use epoll;                # Linux event mechanism
    multi_accept on;
}
```

 - Buffer & Timeout Optimization
```nginx
http {
    client_body_buffer_size 128k;
    client_max_body_size 20m;
    client_header_buffer_size 1k;
    
    keepalive_timeout 65;
    keepalive_requests 1000;
    
    # Gzip compression
    gzip on;
    gzip_types text/plain text/css application/json application/javascript;
}
```

---


**12. Enterprise Enhancements**

**A. Advanced Application-Level Monitoring (APM)**
- Integrate tools like New Relic, Datadog APM, and Elastic APM for real-time web transaction tracing, error detection, and performance analytics.
- Instrument web apps for latency, throughput, slow queries, distributed tracing, and user experience.


**B. Automated Certificate Management (Let's Encrypt, Certbot)**
- Use Certbot for free SSL/TLS certificates and auto-renewal:
  ```bash
  sudo dnf install certbot python3-certbot-apache
  sudo certbot --apache
  
  # For Nginx:
  sudo dnf install certbot python3-certbot-nginx
  sudo certbot --nginx
  
  # Schedule renewal:
  echo "0 0 * * * certbot renew --quiet" | sudo tee /etc/cron.d/certbot-renew
  ```
- Integrate certificate lifecycle management with monitoring and alerting.


**C. Infrastructure as Code (IaC)**
- Use Terraform and Ansible for automated, repeatable deployments of web servers, load balancers, firewalls, certificates, and DNS.
- Example: Terraform for AWS EC2 + Ansible for Apache setup.
- Store configurations in version control and integrate with CI/CD for automated provisioning and rollback.


**D. Containerized Web Servers (Docker, Kubernetes Ingress)**
- Deploy web servers as Docker containers for portability and scalability:
  - Example:  
    ```bash
    docker run -d -p 80:80 --name webserver -v /site:/usr/share/nginx/html nginx
    ```
    
- Use Kubernetes with Ingress controllers for scalable, self-healing deployments, SSL termination, and advanced routing.
- Define web apps and load balancers in YAML manifests and manage with `kubectl`.


**E. CI/CD Integration for Automated Updates**
- Connect GitHub/GitLab CI/CD pipelines to build, test, and deploy web server updates automatically.
- Example:  
  - Push to the main branch triggers the Ansible playbook or Docker build/deploy.
  - Use pipeline stages for syntax check (`nginx -t`, `httpd -t`), unit/integration tests, and production rollout.


**F. Web Application Firewall (WAF) Configuration**
- Deploy WAFs (e.g., ModSecurity for Apache/Nginx, AWS WAF, Cloudflare WAF) to block attacks (SQL injection, XSS, etc).
- Configure security rules, monitor logs, and integrate with SIEM for threat detection.
- Example for ModSecurity with Apache:
  ```bash
  sudo dnf install mod_security
  sudo systemctl restart httpd
  ```
- For Nginx: Use open source WAF modules or integrate with cloud WAF services.



---

# Reverse Proxy Server:

----

A reverse proxy is a server that sits in front of one or more web servers, intercepting requests from clients before they reach the origin servers. It acts as a "front-door" for the servers, enhancing security by masking their identities, improving performance through caching and load balancing, and centralizing functions such as SSL encryption. 

**How it works**

Receives a request: 
- A client, which may be any web browser, requests a website. The request does not directly reach the origin server; instead, it first reaches the reverse proxy.
  
Forwards the request to the backend server:
- Now, the reverse proxy sends the request to the appropriate server, which may be a web server or a microservice.

Returns the response:
- The backend server processes the request and sends the response back to the reverse proxy, which then returns it to the original client.

<img width="2172" height="2780" alt="image" src="https://github.com/user-attachments/assets/ee3aa5ad-563a-45b8-9495-49dc555ba236" />


**Advantages**

Improved security:
- A reverse proxy conceals the IP addresses and properties of the backend servers, protecting them from possible attacks, such as those related to DDoS. It can also work like a security layer while scanning the requests and blocking malicious traffic.

Improved performance:
- The reverse proxy, by caching frequently accessed content, can serve it directly to clients, reducing the load on backend servers.

Load Balancing: 
- It can distribute the incoming client requests over multiple backend servers to avoid having any single server become a bottleneck and ensure high availability if one of them fails.

Centralized management: 
- Functions like SSL/TLS encryption/decryption, logging, and some security policies can be managed in one place at the level of the reverse proxy, easing maintenance and configuration tasks for the backend servers.

---
---

**1) Install and start Nginx**
```bash
# Debian/Ubuntu
sudo apt update && sudo apt install -y nginx

# RHEL/CentOS/Rocky
sudo dnf install -y nginx || sudo yum install -y nginx

sudo systemctl enable --now nginx
```
- Installs Nginx and ensures it starts on boot.

**2) Minimal reverse proxy**

  - `sudo vi /etc/nginx/conf.d/app.conf`
    
```nginx
server {
    listen 80;
    server_name example.com;

    location / {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host              $host;
        proxy_set_header X-Real-IP         $remote_addr;
        proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }
}
```
- Proxies all traffic to your backend and preserves client info via X-Forwarded-* headers.
- Conservative timeouts; adjust for your app’s latency.

**3) Validate and reload**
```bash
sudo nginx -t && sudo systemctl reload nginx
```
- Checks syntax and reloads without dropping connections.


---
---

**1) What Nginx as a Reverse Proxy Actually Does**
- Sits in front of your app(s) and forwards client requests.
- Gives you TLS termination, load balancing, caching, compression, rate limiting, IP controls, and consistent logs.
- Note: Nginx doesn’t minify CSS/JS or optimize images—that belongs in your build/CDN.


**2) Small but Important Setup Steps**
```bash
# Open firewall (if applicable)
sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --reload


# SELinux (if enforcing and proxying to remote backends)
sudo setsebool -P httpd_can_network_connect 1
```
- Let's traffic in and allow Nginx to talk to upstreams when SELinux is enforced.


**3) Good Defaults in nginx.conf**

  - `sudo vi /etc/nginx/nginx.conf`
    
```nginx
user  nginx;
worker_processes auto;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;
    multi_accept on;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Rich logs with upstream timing
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct=$upstream_connect_time '
                    'uht=$upstream_header_time urt=$upstream_response_time';
    access_log /var/log/nginx/access.log main;
    error_log  /var/log/nginx/error.log warn;

    # Sensible performance defaults
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65s;
    types_hash_max_size 4096;
    server_tokens off;  # don’t leak version

    # Compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 5;
    gzip_proxied any;
    gzip_types
        text/plain text/css application/json application/javascript
        application/xml text/xml image/svg+xml;

    # Shared cache for examples below
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:128m
                     max_size=10g inactive=60m use_temp_path=off;

    # Reusable proxy headers (we’ll create this next)
    include /etc/nginx/snippets/proxy-headers.conf;

    include /etc/nginx/conf.d/*.conf;
}
```
- Sets solid defaults for logs, performance, and compression.
- Prepares a cache zone and includes a reusable headers snippet.


**4) Reusable Proxy Headers (avoid repetition)**

  - `sudo vi /etc/nginx/snippets/proxy-headers.conf`
    
```nginx
proxy_set_header Host              $host;
proxy_set_header X-Real-IP         $remote_addr;
proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
proxy_set_header X-Forwarded-Host  $host;
proxy_set_header X-Forwarded-Port  $server_port;

# Keep connections to upstreams alive
proxy_http_version 1.1;
proxy_set_header Connection "";
```
- Standardized headers that many apps expect.
- Improves upstream performance with keepalive connections.

Optional: Brotli (if module exists)
```nginx
# Add inside http { ... }
brotli on;
brotli_comp_level 5;
brotli_types text/plain text/css application/javascript application/json application/xml+rss image/svg+xml;
```
- Smaller responses than gzip on many assets.


**5) Simple Reverse Proxy (clean baseline)**

  - `sudo vi /etc/nginx/conf.d/reverse-proxy.conf`
    
```nginx
server {
    listen 80;
    server_name example.com;

    access_log /var/log/nginx/reverse_access.log main;
    error_log  /var/log/nginx/reverse_error.log warn;

    location / {
        proxy_pass http://backend-server:8080;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_connect_timeout 5s;
        proxy_send_timeout    30s;
        proxy_read_timeout    30s;

        proxy_buffering on;
        proxy_buffers 16 16k;
        proxy_buffer_size 32k;
    }
}
```
- A tidy, production-friendly starting point.
- Buffering helps with slow clients; adjust memory footprint as needed.


**6) Route to Multiple Apps (plus CORS done right)**
```nginx
# Upstreams with keepalive
upstream backend_app   { server 192.168.1.10:3000; server 192.168.1.11:3000; keepalive 64; }
upstream admin_panel   { server 192.168.1.12:4000; keepalive 32; }
upstream api_service   { server 192.168.1.13:5000; keepalive 64; }

server {
    listen 80;
    server_name mydomain.com;

    # Main app
    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Admin
    location /admin/ {
        proxy_pass http://admin_panel/;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Preflight (OPTIONS) for CORS
    location /api/ {
        if ($request_method = OPTIONS) {
            add_header Access-Control-Allow-Origin "*" always;
            add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS" always;
            add_header Access-Control-Allow-Headers "Authorization, Content-Type" always;
            add_header Access-Control-Max-Age 86400 always;
            return 204;
        }
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;
        add_header Access-Control-Allow-Origin "*" always;
    }

    # Serve static files directly
    location /static/ {
        alias /var/www/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```
- Routes different paths to different services.
- Handles CORS preflight cleanly; use specific origins for production if possible.
- alias avoids double /static in paths.


**7) HTTPS the Easy Way (Let’s Encrypt)**
```bash
# Debian/Ubuntu
sudo apt install -y certbot python3-certbot-nginx

# RHEL/Rocky/CentOS
sudo dnf install -y certbot python3-certbot-nginx || sudo yum install -y certbot python3-certbot-nginx

sudo certbot --nginx -d mydomain.com -d www.mydomain.com
sudo systemctl status certbot.timer  # confirm auto-renew
```
- Automatically gets and renews certs, updates Nginx config, and enables HTTP->HTTPS.

**Manual TLS (when you bring your own certs)**
```nginx
server {
    listen 443 ssl http2;
    server_name mydomain.com;

    ssl_certificate     /etc/nginx/ssl/mydomain.crt;
    ssl_certificate_key /etc/nginx/ssl/mydomain.key;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_stapling on;
    ssl_stapling_verify on;
    ssl_trusted_certificate /etc/nginx/ssl/mydomain.chain.pem;  # full chain for OCSP

    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options DENY;
    add_header Content-Security-Policy "default-src 'self'; frame-ancestors 'none'" always;

    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_set_header X-Forwarded-Proto https;
    }
}

server {
    listen 80;
    server_name mydomain.com;
    return 301 https://$host$request_uri;
}
```
- Solid TLS defaults with HTTP/2, HSTS, and OCSP stapling.
- Redirects all plain HTTP to HTTPS.


**8) Caching and Microcaching (safe defaults)**
```nginx
# my_cache defined in http { }

server {
    listen 80;
    server_name mydomain.com;

    # Static via upstream (cacheable forever)
    location ~* \.(?:jpg|jpeg|png|gif|ico|css|js|svg)$ {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_cache my_cache;
        proxy_cache_valid 200 302 1h;
        proxy_cache_valid 404 1m;
        proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;

        add_header X-Cache-Status $upstream_cache_status;

        # Only enable if your upstream wrongly sets cookies on assets
        # proxy_ignore_headers Set-Cookie;
    }

    # API microcache (GET/HEAD)
    location /api/ {
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_cache my_cache;
        proxy_cache_methods GET HEAD;
        proxy_cache_valid 200 302 5s;
        proxy_cache_key "$scheme$request_method$host$request_uri";
        add_header X-Cache-Status $upstream_cache_status;

        # Bypass cache when authenticated
        set $bypass_cache 0;
        if ($http_authorization ~* ".+") { set $bypass_cache 1; }
        if ($cookie_session     ~* ".+") { set $bypass_cache 1; }
        proxy_no_cache     $bypass_cache;
        proxy_cache_bypass $bypass_cache;
    }

    # Dynamic pages: no cache
    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_no_cache 1;
        proxy_cache_bypass 1;
    }
}
```
- Caches safe content (static, cacheable GETs) and avoids caching authenticated requests.
- X-Cache-Status helps you see hits/misses in logs.


**9) Load Balancing + Failover (open-source friendly)**
```nginx
upstream backend_pool {
    least_conn;  # smoother under uneven loads
    server 192.168.1.10:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.11:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.12:8080 backup;
    keepalive 128;
}

server {
    listen 80;
    server_name mydomain.com;

    location / {
        proxy_pass http://backend_pool;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_next_upstream_tries 2;
        proxy_next_upstream_timeout 10s;
    }

    # Pass-through health endpoint
    location /health {
        proxy_pass http://backend_pool/health;
        include /etc/nginx/snippets/proxy-headers.conf;
        access_log off;
    }
}
```
- Uses passive health checks; NGINX Plus has active checks.
- least_conn is often better than round robin for APIs.


**10) WebSockets and SSE (don’t forget these bits)**
```nginx
server {
    listen 80;
    server_name mydomain.com;

    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # WebSocket
    location /ws/ {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_read_timeout 3600s;
        proxy_send_timeout 3600s;
        proxy_buffering off;
    }

    # Server-Sent Events
    location /events/ {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_buffering off;
        proxy_read_timeout 3600s;
    }
}
```
- Upgrade/Connection headers are required for WebSockets.
- Disable buffering for real-time streams.


**11) Security: Rate Limits, Access Control, Hardening**
```nginx
# Define zones
limit_req_zone  $binary_remote_addr zone=api_rps:10m  rate=10r/s;
limit_req_zone  $binary_remote_addr zone=auth_rpm:10m rate=5r/m;
limit_conn_zone $binary_remote_addr zone=perip:10m;

server {
    listen 80;
    server_name mydomain.com;

    # API rate limits
    location /api/ {
        limit_req zone=api_rps burst=20 nodelay;
        limit_conn perip 20;
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Stricter for auth
    location /api/auth/ {
        limit_req zone=auth_rpm burst=5 nodelay;
        limit_conn perip 5;
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Restrict admin by IP
    location /admin/ {
        allow 192.168.1.0/24;
        allow 10.0.0.1;
        deny all;
        proxy_pass http://admin_panel;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    client_max_body_size 20m;  # adjust for uploads
    server_tokens off;

    # Block sensitive file paths
    location ~* \.(?:env|git|svn)(?:/|$) { return 403; }

    # Optional: block obvious scanners (use sparingly)
    if ($http_user_agent ~* (nikto|sqlmap|wget|curl)) { return 403; }
}
```
- Puts guardrails around abusive traffic and sensitive areas.
- Bumps upload limit for APIs that accept files.


**12) Performance: Buffers and Timeouts that Make Sense**
```nginx
server {
    listen 80;
    server_name mydomain.com;

    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_buffering on;
        proxy_buffer_size 16k;
        proxy_buffers 16 16k;
        proxy_busy_buffers_size 64k;

        proxy_connect_timeout 5s;
        proxy_send_timeout 20s;
        proxy_read_timeout 20s;
    }
}
```
- Buffers help Nginx absorb bursts and slow clients.
- Timeouts protect you from hanging upstreams.


**13) Observability (know what’s happening)**
```nginx
# Local status (stub_status)
server {
    listen 127.0.0.1:8081;
    location /nginx_status {
        stub_status;
        access_log off;
        allow 127.0.0.1;
        deny all;
    }
}
```
- Get active connections and basic counters locally; scrape with a Prometheus exporter if needed.


**14) Operate and Validate**
```bash
# Validate and dump config
sudo nginx -t
sudo nginx -T

# Reload without dropping connections
sudo systemctl reload nginx

# Tail logs
sudo tail -f /var/log/nginx/access.log /var/log/nginx/error.log

# Sanity checks
curl -I http://mydomain.com
curl -kI https://mydomain.com

# Simple load test (if wrk installed)
wrk -t4 -c100 -d30s http://mydomain.com/
```
- Always test the config before reload.
- access.log + upstream timings are your best friend.


**15) Troubleshooting**
- 502 Bad Gateway:
    - Upstream down, DNS wrong, firewall/SELinux blocking. Test with curl from the Nginx host.
- 504 Gateway Timeout:
    - Upstream is slow; raise proxy_read_timeout or fix backend performance.
- 413 Request Entity Too Large:
    - Increase client_max_body_size.
- 499 Client Closed Request:
    - User cancelled or closed connection; often harmless.
- TLS issues:
    - Check full chain, SNI, and OCSP trusted chain; certbot renew logs help.


**16) Running Behind Another Proxy/CDN (real client IPs)**
```nginx
# Inside http { ... }
real_ip_header X-Forwarded-For;
set_real_ip_from 10.0.0.0/8;
set_real_ip_from 172.16.0.0/12;
set_real_ip_from 192.168.0.0/16;
# For Cloudflare, add their published IPs
# real_ip_recursive on;  # Use with care—trust chain matters
```
- Restores $remote_addr to the actual client when traffic comes via a trusted proxy/LB.


**17) A Practical Production Server (HTTP only example)**

  - `sudo vi /etc/nginx/conf.d/app.conf`
    
```nginx
upstream backend_servers {
    least_conn;
    server 192.168.1.10:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.11:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.12:8080 backup;
    keepalive 128;
}

server {
    listen 80;
    server_name mydomain.com www.mydomain.com;

    # Baseline security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header Referrer-Policy "strict-origin-when-cross-origin";

    # App
    location / {
        proxy_pass http://backend_servers;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_connect_timeout 5s;
        proxy_send_timeout    20s;
        proxy_read_timeout    20s;
    }

    # Static via upstream (cache hard)
    location ~* \.(?:js|css|png|jpg|jpeg|gif|ico|svg)$ {
        proxy_pass http://backend_servers;
        include /etc/nginx/snippets/proxy-headers.conf;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # Health for external monitors
    location = /nginx-health {
        access_log off;
        add_header Content-Type text/plain;
        return 200 "healthy\n";
    }
}
```

- A clean, copy/paste-able starting point.
- Add HTTPS via certbot when you’re ready.
